# Wavelet Interface Network (WIN) for Audio Deepfake Detection

![Python(Preferred)](https://img.shields.io/badge/Python-3.12%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-red)
![Kaggle](https://img.shields.io/badge/Kaggle-Notebook%20Ready-20BEFF)

This repository contains the official implementation of the **Wavelet Interface Network (WIN)** for audio deepfake detection using wavelet-based feature mapping and transformer-style modeling.

The proposed model integrates signal preprocessing, learnable Sinc-based frontend, positional aggregation, and multi-wavelet attention for robust anti-spoofing.

The framework supports multiple analytic wavelet families, enabling systematic ablation and comparative analysis.

---

## ğŸ“Œ Key Features

- End-to-end learning from raw waveform
- Pre-emphasis filtering
- Sinc-based convolutional frontend
- CNN feature extraction
- Positional encoding
- Multi-wavelet attention mechanism
- Transformer-style encoder
- Attention-based sequence pooling
- Support for multiple wavelet families
- EER and t-DCF evaluation
- FLOPs and parameter analysis

---

## ğŸ“ Project Structure

```

WIN/
â”‚
â”œâ”€â”€ train.py              # Training script
â”œâ”€â”€ test.py               # Testing / evaluation
â”œâ”€â”€ model_info.py         # Parameter & FLOPs analysis (optional)
â”‚
â”œâ”€â”€ config.py             # Configuration
â”œâ”€â”€ requirements.txt      # Dependencies
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ device.py
â”‚   â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataloader.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ frontend.py
â”‚   â”œâ”€â”€ encoder.py
â”‚   â”œâ”€â”€ WIN_classifier.py
â”‚   â””â”€â”€ WIN.py
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_forward.py
â”‚
â””â”€â”€ README.md

````

---

## âš™ï¸ Requirements

Install dependencies:

```bash
pip install -r requirements.txt
````

Optional tools for model analysis:

```bash
pip install torchinfo fvcore
```

---

## ğŸ“Š Dataset Structure

Organize your dataset as:

```
dataset_root/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ bonafide/
â”‚   â””â”€â”€ spoof/
â”œâ”€â”€ dev/
â”‚   â”œâ”€â”€ bonafide/
â”‚   â””â”€â”€ spoof/
â””â”€â”€ test/
    â”œâ”€â”€ bonafide/
    â””â”€â”€ spoof/
```

Update dataset paths in `config.py`.

---

## ğŸš€ Training

Run training:

```bash
python train.py
```

The best model is saved automatically based on validation EER.

---

## ğŸ§ª Testing

Run evaluation:

```bash
python test.py
```

Outputs:

* Final EER
* Minimum t-DCF

---

## ğŸ” Sanity Check

Verify forward pass and architecture:

```bash
python tests/test_forward.py
```

This performs a dummy inference to validate model consistency.

---

## ğŸ“ Model Complexity

Check parameters and FLOPs:

```bash
python model_info.py
```

This reports:

* Trainable parameters
* Total parameters
* Model size
* MACs / FLOPs
* GFLOPs per second
* Layer-wise breakdown

---

## ğŸ§  Model Architecture

The overall processing pipeline is:

```
Waveform
   â†“
Pre-Emphasis
   â†“
Sinc + CNN Frontend
   â†“
Positional Encoding
   â†“
Multi-Wavelet Transformer
   â†“
Sequence Pooling
   â†“
Classifier
```

---

## ğŸŒŠ Supported Wavelet Families

The Wavelet-FAN attention module supports the following wavelet types:

| Config Name | Wavelet Family               |
| ----------- | ---------------------------- |
| bump        | Bump Wavelet                 |
| morlet      | Morlet Wavelet               |
| dog         | Derivative of Gaussian (DoG) |
| mexican     | Mexican Hat (Ricker)         |
| morse       | Generalized Morse            |

Wavelet type can be selected in `config.py`:

```python
WAVELET_TYPE = "bump"   # default
```

---

## ğŸ“ˆ Evaluation Metrics

The following metrics are used:

* Equal Error Rate (EER)
* Tandem Detection Cost Function (t-DCF)

Implemented in `utils/metrics.py`.

---

## ğŸ”§ Configuration

All hyperparameters and experiment settings are defined in:

```
config.py
```

This includes:

* Dataset paths
* Training parameters
* Model dimensions
* Wavelet selection

Modify this file to conduct different experiments.

---

## ğŸ’¾ Checkpoints

Trained models are saved at:

```
WIN.pth
```

Defined in `config.py` as `SAVE_PATH`.

---

## ğŸ“„ Citation

If you use this work in your research, please cite:

```
@article{win2026,
  title={Wavelet Interface Network for Audio Deepfake Detection},
  author={Shah, Arth J. and Pandey, Aniket and Patil, Hemant A.},
  journal={Journal/Conference},
  year={2026}
}
```

(Replace with the final publication details.)

---

## ğŸ“œ License

This project is intended for academic and research use only.

For commercial usage, please contact the authors.

---

## ğŸ™ Acknowledgements

* ASVspoof Challenge
* PyTorch
* torchaudio
* fvcore
* torchinfo

---

## ğŸ“¬ Contact

Authors:
Arth J. Shah
Aniket Pandey
Hemant A. Patil

Email:
[202521004@dau.ac.in](mailto:202521004@dau.ac.in)
[202411001@dau.ac.in](mailto:202411001@dau.ac.in)

```
If youâ€™d like, next I can help you prepare a **â€œReproducibility Checklistâ€ section** for top-tier conferences/journals.
```
