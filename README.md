# Wavelet Interface Network (WIN) for Audio Deepfake Detection

![Python(Preferred)](https://img.shields.io/badge/Python-3.12%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-red)
![Kaggle](https://img.shields.io/badge/Kaggle-Notebook%20Ready-20BEFF)

This repository contains the official implementation of the **Wavelet Integrated Network (WIN)** originally applied for Audio Deepfake Detection using wavelet-based feature mapping modeling.

---

## Project Structure

```

WIN/
â”‚
â”œâ”€â”€ train.py              # Training script (Python implementation)
â”œâ”€â”€ test.py               # Testing / evaluation
â”œâ”€â”€ model_info.py         # Parameter & FLOPs analysis (optional)
â”‚
â”œâ”€â”€ config.py             # Configuration
â”œâ”€â”€ requirements.txt      # Dependencies
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ device.py
â”‚   â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataloader.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ frontend.py
â”‚   â”œâ”€â”€ encoder.py
â”‚   â”œâ”€â”€ WIN_classifier.py
â”‚   â””â”€â”€ WIN.py
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_forward.py
â”‚
â”œâ”€â”€ Notebooks/            # Original experimental notebooks (implemented in paper)
â”‚   â”œâ”€â”€ Backend/          # Jupyter notebooks for each wavelet
â”‚   â”‚   â”œâ”€â”€ bump.ipynb
â”‚   â”‚   â”œâ”€â”€ morlet.ipynb
â”‚   â”‚   â”œâ”€â”€ dog.ipynb
â”‚   â”‚   â”œâ”€â”€ mex_h.ipynb
â”‚   â”‚   â””â”€â”€ morse.ipynb
â”‚   â”‚
â”‚   â””â”€â”€ Backend_models/   # Pre-trained models (.pth)
â”‚       â”œâ”€â”€ bump.pth
â”‚       â”œâ”€â”€ morlet.pth
â”‚       â”œâ”€â”€ dog.pth
â”‚       â”œâ”€â”€ mex_h.pth
â”‚       â””â”€â”€ morse.pth
â”‚
â””â”€â”€ README.md

````

---

## Requirements

Install dependencies:

```bash
pip install -r requirements.txt
````

Optional tools for model analysis:

```bash
pip install torchinfo fvcore
```

---

## Dataset Structure

Organize your dataset as:

```
dataset_root/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ bonafide/
â”‚   â””â”€â”€ spoof/
â”œâ”€â”€ dev/
â”‚   â”œâ”€â”€ bonafide/
â”‚   â””â”€â”€ spoof/
â””â”€â”€ test/
    â”œâ”€â”€ bonafide/
    â””â”€â”€ spoof/
```

Update dataset paths in `config.py`.
```
---

## Reproducibility and Jupyter Notebooks

The original experiments and model development were conducted using Jupyter notebooks on the Kaggle platform.

To ensure full reproducibility, this repository includes the complete set of original notebooks and trained models.

### Notebook Organization

The `Notebooks/` directory is organized as follows:

```

Notebooks/
â”œâ”€â”€ Backend/          # Training and evaluation notebooks
â”‚   â”œâ”€â”€ bump.ipynb
â”‚   â”œâ”€â”€ morlet.ipynb
â”‚   â”œâ”€â”€ dog.ipynb
â”‚   â”œâ”€â”€ mex_h.ipynb
â”‚   â””â”€â”€ morse.ipynb
â”‚
â””â”€â”€ Backend_models/   # Corresponding trained models
â”œâ”€â”€ bump.pth
â”œâ”€â”€ morlet.pth
â”œâ”€â”€ dog.pth
â”œâ”€â”€ mex_h.pth
â””â”€â”€ morse.pth

````

Each notebook in `Backend/` contains the complete experimental pipeline for a specific wavelet type, including:

- Data loading  
- Preprocessing  
- Model construction  
- Training loop  
- Validation  
- Testing  
- Metric computation  

The `Backend_models/` directory contains the trained model checkpoints generated by these notebooks.

### Relationship Between Notebooks and Python Scripts

Two complementary implementations are provided:

1. **Notebook-based implementation (Original)**
   - Located in `Notebooks/Backend/`
   - Used for initial experimentation and result generation
   - Suitable for interactive analysis and visualization

2. **Modular Python implementation (Reproducible)**
   - Implemented using `train.py`, `test.py`, and `models/`
   - Designed for large-scale experiments and reproducibility
   - Matches the logic and configuration of the notebook experiments

Both implementations follow the same preprocessing, model architecture, and evaluation protocol.

### Reproducing Original Results

To reproduce the results reported in the notebooks:

1. Open the corresponding notebook in `Notebooks/Backend/`
2. Set dataset paths according to your environment
3. Run all cells sequentially
4. The trained model will be saved in `Notebooks/Backend_models/`

To reproduce results using the modular implementation:

```bash
python train.py
python test.py
````

Ensure that `config.py` matches the experimental settings used in the notebooks.

---


---

## Training

Run training:

```bash
python train.py
```

The best model is saved automatically based on validation EER.

---

## Testing

Run evaluation:

```bash
python test.py
```

Outputs:

* Final EER

---

## Sanity Check

Verify forward pass and architecture:

```bash
python tests/test_forward.py
```

This performs a dummy inference to validate model consistency.

---

## Model Complexity

Check parameters and FLOPs:

```bash
python model_info.py
```

This reports:

* Trainable parameters
* Total parameters
* Model size
* MACs / FLOPs
* GFLOPs per second
* Layer-wise breakdown

---

## Model Architecture

The overall processing pipeline is:

```
Waveform
   â†“
Pre-Emphasis
   â†“
Sinc + CNN Frontend
   â†“
Positional Encoding
   â†“
Multi-Wavelet Transformer
   â†“
Sequence Pooling
   â†“
Classifier
```

---

## Supported Wavelet Families

The Wavelet feature maps in `WIN_classifier.py` module supports the following wavelet types:

| Config Name | Wavelet Family               |
| ----------- | ---------------------------- |
| bump        | Bump Wavelet                 |
| morlet      | Morlet Wavelet               |
| dog         | Derivative of Gaussian (DoG) |
| mex_h       | Mexican Hat (Ricker)         |
| morse       | Generalized Morse Wavelet    |

Wavelet type can be selected in `config.py`:

```python
WAVELET_TYPE = "bump"   # default bump ["bump", "morlet", "dog", "morse", "mex_h"]
```

---

## Evaluation Metrics

The following metrics are used:

* Equal Error Rate (EER)
* Tandem Detection Cost Function (t-DCF)

Implemented in `utils/metrics.py`.

---

## Configuration

All hyperparameters and experiment settings are defined in:

```
config.py
```

This includes:

* Dataset paths
* Training parameters
* Model dimensions
* Wavelet selection

Modify this file to conduct different experiments.

---

## Checkpoints

Trained models are saved at:

```
WIN.pth
```

Defined in `config.py` as `SAVE_PATH`.

---

## Citation

If you use this work in your research, please cite:

```
@article{win2026,
  title={Wavelet Interface Network for Audio Deepfake Detection},
  author={Shah, Arth J. and Pandey, Aniket and Patil, Hemant A.},
  journal={Journal/Conference},
  year={2026}
}
```
---

## License

This project is intended for academic and research use only.

For commercial usage, please contact the authors.

---

## ğŸ™ Acknowledgements

* xxx
* yyy

---

## ğŸ“¬ Contact

Authors:
Arth J. Shah
Aniket Pandey
Hemant A. Patil

Email:
[202521004@dau.ac.in](mailto:202521004@dau.ac.in)
[202411001@dau.ac.in](mailto:202411001@dau.ac.in)
