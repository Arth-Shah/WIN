# Wavelet Integrated Network (WIN) for Audio Deepfake Detection

![Python(Preferred)](https://img.shields.io/badge/Python-3.12%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-red)
![Kaggle](https://img.shields.io/badge/Kaggle-Notebook%20Ready-20BEFF)

This repository contains the official implementation of the **Wavelet Integrated Network (WIN)** originally applied for Audio Deepfake Detection using wavelet-based feature mapping modeling.

---

## Project Structure

```

WIN/
│
├── train.py              # Training script (Python implementation)
├── test.py               # Testing / evaluation
├── model_info.py         # Parameter & FLOPs analysis (optional)
│
├── config.py             # Configuration
├── requirements.txt      # Dependencies
│
├── utils/
│   ├── device.py
│   └── metrics.py
│
├── data/
│   └── dataloader.py
│
├── models/
│   ├── preprocess.py
│   ├── frontend.py
│   ├── encoder.py
│   ├── WIN_classifier.py
│   └── WIN.py
│
├── tests/
│   └── test_forward.py
│
├── Notebooks/            # Original experimental notebooks (implemented in paper)
│   ├── Backend/          # Jupyter notebooks for each wavelet
│   │   ├── bump.ipynb
│   │   ├── morlet.ipynb
│   │   ├── dog.ipynb
│   │   ├── mex_h.ipynb
│   │   └── morse.ipynb
│   │
│   └── Backend_models/   # Model checkpoints (.pth)
│       ├── bump.pth
│       ├── morlet.pth
│       ├── dog.pth
│       ├── mex_h.pth
│       └── morse.pth
├── Dataset_Formation (Contains codes for forming dataset in particular format)
│
└── README.md

````

---

## Requirements

Install dependencies:

```bash
pip install -r requirements.txt
````

Optional tools for model analysis:

```bash
pip install torchinfo fvcore
```

---
## Dataset Structure

This project supports ASVspoof 2019 and ASVspoof 2021 (LA) datasets.

### Required Format

Datasets must be organized as:

```

dataset_root/
├── train/
│   ├── bonafide/
│   └── spoof/
├── dev/
│   ├── bonafide/
│   └── spoof/
└── test/
│   ├── bonafide/
│   └── spoof/

```

Update paths in `config.py` accordingly if using python.

The `Dataset_Formation/` directory provides scripts to automatically organize ASVspoof 2019 and ASVspoof 2021 (LA) datasets into the required format once downloaded zip (from [original ASVSpoof website](https://www.asvspoof.org/database)) and extracted. Users are recommended to use these scripts for consistency.

Preprocessed Datasets zip download (Kaggle.com)
- ASVspoof 2021 (LA):  
  https://www.kaggle.com/datasets/artharking/asv-2021-la-test

- ASVspoof 2019 (AA):  
  https://www.kaggle.com/datasets/artharking/asv-19-aa

These can be used directly without additional preprocessing.

---

## Reproducibility and Jupyter Notebooks

The original experiments and model development were conducted using Jupyter notebooks on the Kaggle platform.

To ensure full reproducibility, this repository includes the complete set of original notebooks and trained models.

### Notebook Organization

The `Notebooks/` directory is organized as follows:

```

Notebooks/
├── Backend/          # Training and evaluation notebooks
│   ├── bump.ipynb
│   ├── morlet.ipynb
│   ├── dog.ipynb
│   ├── mex_h.ipynb
│   └── morse.ipynb
│
└── Backend_models/   # Corresponding trained model checkpoints
├── bump.pth
├── morlet.pth
├── dog.pth
├── mex_h.pth
└── morse.pth

````

Each notebook in `Backend/` contains the complete experimental pipeline for a specific wavelet type.

The `Backend_models/` directory contains the trained model checkpoints generated by these notebooks.

### Relationship Between Notebooks and Python Scripts

Two complementary implementations are provided:

1. **Notebook-based implementation (Original and Recommended)**
   - Located in `Notebooks/Backend/`
   - Used for initial experimentation and result generation
   - Suitable for interactive analysis and visualization.
2. **For modular Python implementation please follow below steps**

---

## Training

Run training:

```bash
python train.py
```

The best model is saved automatically based on validation EER.

---

## Testing

Run evaluation:

```bash
python test.py
```

Outputs:

* Final EER

---

## Sanity Check

Verify forward pass and architecture:

```bash
python tests/test_forward.py
```

This performs a dummy inference to validate model consistency.

---

## Model Complexity

Check parameters and FLOPs:

```bash
python model_info.py
```

This reports:

* Trainable parameters
* Total parameters
* Model size
* MACs / FLOPs
* GFLOPs per second
* Layer-wise breakdown

---

## Model Architecture

The overall processing pipeline is:

```
Waveform
   ↓
Pre-Emphasis
   ↓
Sinc + CNN Frontend
   ↓
Positional Encoding
   ↓
Multi-Wavelet Classifier
   ↓
Sequence Pooling
   ↓
Classification
```

---

## Supported Wavelet Families

The Wavelet feature maps in `WIN_classifier.py` module supports the following wavelet types:

| Config Name | Wavelet Family               |
| ----------- | ---------------------------- |
| bump        | Bump Wavelet                 |
| morlet      | Morlet Wavelet               |
| dog         | Derivative of Gaussian (DoG) |
| mex_h       | Mexican Hat (Ricker)         |
| morse       | Generalized Morse Wavelet    |

Wavelet type can be selected in `config.py`:

```python
WAVELET_TYPE = "bump"   # default bump ["bump", "morlet", "dog", "morse", "mex_h"]
```

---

## Evaluation Metrics

The following metrics are used:

* Equal Error Rate (EER)
* Tandem Detection Cost Function (t-DCF)  
Employing t-DCF for CM task would give value 1, as t-DCF is not employed for CM task, we in future plan to extend system for End-to-End ASV system.

Implemented in `utils/metrics.py`.

---

## Configuration

All hyperparameters and experiment settings are defined in:

```
config.py
```

This includes:

* Dataset paths
* Training parameters
* Model dimensions
* Wavelet selection

Modify this file to conduct different experiments.

---

## Checkpoints

Trained models are saved at:

```
WIN.pth
```

Defined in `config.py` as `SAVE_PATH`.

---

## Citation

If you use this work in your research, please cite:

```
@article{win2026,
  title={WIN: Wavelet Integrated Network for Anti-Spoofing},
  author={Shah, Arth J. and Pandey, Aniket and Patil, Hemant A.},
  journal={Submitted to IEEE SPS Letters (Under Review)},
  year={2026}
}
```
---

## License

This project is intended for academic and research use only.

For commercial usage, please contact the authors.

---

## Acknowledgements

This repository is built on top of several open source projects. 
- [AASIST repo](https://github.com/clovaai/aasist)
- [Rawformer Repo](https://github.com/rst0070/Rawformer-implementation-anti-spoofing)
- [FAN repo](https://github.com/YihongDong/FAN)
- [FANFormer Repo](https://github.com/YihongDong/FANformer) (ATF module inspiration)

---

## Contact

Authors:
Arth J. Shah
Aniket Pandey
Hemant A. Patil

Email:
[202521004@dau.ac.in](mailto:202521004@dau.ac.in) , 
[202411001@dau.ac.in](mailto:202411001@dau.ac.in) , 
[arth123shah@gmail.com](mailto:arth123shah@gmail.com) , 
[aniket25403@gmail.com](mailto:aniket25403@gmail.com) 
